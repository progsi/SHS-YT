{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/SHS-YT.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "utils.get_mean_sim(\"coverhunter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby([\"set_id\", \"nlabel\"]).describe().reset_index().groupby(\"nlabel\").describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def krippendorff_pivot(df_hit_pivot: pd.DataFrame):\n",
    "    import krippendorff\n",
    "    df_hit_pivot = df_hit_pivot[[f\"worker_ind{i}\" for i in range(5)]]\n",
    "    try:\n",
    "        return round(krippendorff.alpha(df_hit_pivot.T, level_of_measurement='ordinal'), 2)\n",
    "    except AssertionError:\n",
    "        return None\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "krippendorff_pivot(data[[f\"worker_ind{i}\" for i in range(5)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_sample_groups(x):\n",
    "    if x != x: # this works to detect nans\n",
    "        return x\n",
    "    else:\n",
    "        return x.replace(\"re-move_favs\", \n",
    "                         \"DisAgrMus\").replace(\"ditto_favs\", \n",
    "                                     \"DisAgrTxt\").replace(\"mutual_unconfident\", \"MutUnc\")\n",
    "\n",
    "# Create a list of worker columns\n",
    "worker_cols = [f'worker_ind{i}' for i in range(5)]\n",
    "\n",
    "# Create a new dataframe with the relevant columns\n",
    "pivot_data = data[worker_cols + ['sample_group', 'label']]\n",
    "\n",
    "# Group by 'sample_group' and 'mv_nlabel' and count occurrences\n",
    "pivot_table = pivot_data.groupby(['sample_group', 'label']).size().unstack(fill_value=0)\n",
    "\n",
    "custom_sort_order = ['Match', 'Version', 'Other', 'No Music']\n",
    "\n",
    "# Reindex the DataFrame based on the custom sort order\n",
    "pivot_table = pivot_table.reindex(columns=custom_sort_order)\n",
    "  \n",
    "for sample_group in data.sample_group.unique():\n",
    "    pivot_table.loc[sample_group, \"Agreement\"] = krippendorff_pivot(data.query(f\"sample_group == '{sample_group}'\"))\n",
    "    pivot_table.loc[sample_group, \"Curated\"] = int(data.query(f\"sample_group == '{sample_group}'\").label_expert.count())\n",
    "    pivot_table.loc[sample_group, \"Relabeled\"] = int(len(data.query(f\"sample_group == '{sample_group}' & ((~nlabel_expert.isna() & nlabel_expert != nlabel_mturk))\")))\n",
    "\n",
    "for label in data.label.unique():\n",
    "    pivot_table.loc[\"Curated\", label] = int(len(data.query(f\"label == '{label}' & (origin == 'expert')\")))\n",
    "    pivot_table.loc[\"Relabeled\", label] = int(len(data.query(f\"label == '{label}' & ((~nlabel_expert.isna() & nlabel_expert != nlabel_mturk))\")))\n",
    "\n",
    "pivot_table.index = pivot_table.index.to_series().apply(rename_sample_groups).fillna(\"None\")\n",
    "pivot_table = pivot_table.rename_axis(\"Group\").rename_axis(\"Label\", axis=1)\n",
    "pivot_table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlaps with existing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Da-Tacos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_datacos = pd.read_csv(\"data/da-tacos.csv\", sep=\";\")\n",
    "data[data.yt_id.isin(data_datacos.yt_id)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHS100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shs100k = pd.read_csv(\"data/shs100k.csv\", sep=\";\")\n",
    "pd.merge(data[[\"set_id\", \"yt_id\", \"label\"]], \n",
    "         data_shs100k[[\"set_id\", \"yt_id\", \"title\", \"subset\"]], \n",
    "         on=\"yt_id\", suffixes=[\"_YT\", \"_SHS\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
